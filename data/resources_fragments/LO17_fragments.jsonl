{"fragment_id": "F001", "resource_id": "R001", "uv_id": "LO17", "fragment_type": "section", "section_title": "Introduction to Machine Learning (6.036)", "start_char": 0, "end_char": 377, "text": "This course introduces principles, algorithms, and applications of machine learning from the point of view of modeling and prediction. It includes formulation of learning problems and concepts of representation, over‑fitting, and generalization. These concepts are exercised in supervised learning and reinforcement learning, with applications to images and temporal sequences.", "token_count": 49}
{"fragment_id": "F002", "resource_id": "R002", "uv_id": "LO17", "fragment_type": "section", "section_title": "Introduction to Computational Thinking and Data Science (6.0002)", "start_char": 0, "end_char": 482, "text": "6.0002 is the continuation of 6.0001 Introduction to Computer Science and Programming in Python and is intended for students with little or no programming experience. It aims to provide students with an understanding of the role computation can play in solving problems and to help students, regardless of their major, feel justifiably confident of their ability to write small programs that allow them to accomplish useful goals. The class uses the Python 3.5 programming language.", "token_count": 75}
{"fragment_id": "F003", "resource_id": "R003", "uv_id": "LO17", "fragment_type": "section", "section_title": "Matrix Methods in Data Analysis, Signal Processing, and Machine Learning (18.065)", "start_char": 0, "end_char": 302, "text": "Linear algebra concepts are key for understanding and creating machine learning algorithms, especially as applied to deep learning and neural networks. This course reviews linear algebra with applications to probability and statistics and optimization–and above all a full explanation of deep learning.", "token_count": 42}
{"fragment_id": "F004", "resource_id": "R004", "uv_id": "LO17", "fragment_type": "section", "section_title": "Problem Set 1: Space Cows Transportation", "start_char": 0, "end_char": 185, "text": "This programming assignment provides a zip folder containing one PDF file, two text files and three Python scripts. Students develop code to solve the Space Cows transportation problem.", "token_count": 28}
{"fragment_id": "F005", "resource_id": "R005", "uv_id": "LO17", "fragment_type": "section", "section_title": "Problem Set 2: Fastest Way to Get Around MIT", "start_char": 0, "end_char": 204, "text": "This programming assignment provides a zip folder containing one PDF file, one text file and two Python scripts. The task focuses on finding the fastest way to get around MIT using algorithmic approaches.", "token_count": 33}
{"fragment_id": "F006", "resource_id": "R006", "uv_id": "LO17", "fragment_type": "section", "section_title": "Problem Set 3: Robot Simulation", "start_char": 0, "end_char": 178, "text": "This programming assignment contains a zip folder with one PDF file, four compiled Python files and four Python scripts. Students simulate robots moving in a defined environment.", "token_count": 27}
{"fragment_id": "F007", "resource_id": "R007", "uv_id": "LO17", "fragment_type": "section", "section_title": "Problem Set 4: Simulating the Spread of Disease and Bacteria Population", "start_char": 0, "end_char": 172, "text": "This programming assignment includes a zip folder with one PDF file and two Python scripts. Learners simulate the spread of disease and the growth of a bacteria population.", "token_count": 28}
{"fragment_id": "F008", "resource_id": "R008", "uv_id": "LO17", "fragment_type": "section", "section_title": "Data Science: A First Introduction (Textbook)", "start_char": 0, "end_char": 966, "text": "This chapter of the open textbook provides an introduction to data science and the R programming language. It walks through an entire data analysis to get readers hands‑on experience, introducing different types of data analysis question, fundamental programming concepts in R, and the basics of loading, cleaning, and visualizing data. Readers learn to identify types of data analysis questions, load the tidyverse package, read tabular data using read_csv, create new variables and objects in R, subset data frames with filter and select, arrange and slice rows, mutate columns, and visualize data with ggplot bar plots. The chapter explores a dataset of languages spoken at home by Canadian residents to ask which Aboriginal languages are most commonly reported as mother tongues, emphasizing the importance of understanding the data and problem domain and warning that data science cannot be done without domain expertise and awareness of data collection biases.", "token_count": 147}
{"fragment_id": "F009", "resource_id": "R009", "uv_id": "LO17", "fragment_type": "section", "section_title": "Data Carpentry Lessons (General)", "start_char": 0, "end_char": 752, "text": "Data Carpentry develops domain‑specific lessons for workshops. These lessons are distributed under the CC‑BY license and are free for reuse or adaptation with attribution. Data Carpentry workshops teach researchers the skills most relevant to their domain using examples from their own work. The Astronomy curriculum teaches database operations and creating publication‑quality data visualisations. The Ecology workshop uses a tabular ecology dataset to teach data cleaning, management, analysis and visualization with no prerequisites. Lessons in English for ecology include Data Organization in Spreadsheets, Data Cleaning with OpenRefine, Data Management with SQL, Data Analysis and Visualization in R, and Data Analysis and Visualization in Python.", "token_count": 103}
{"fragment_id": "F010", "resource_id": "R010", "uv_id": "LO17", "fragment_type": "section", "section_title": "Machine Learning in Python with scikit‑learn (FUN MOOC)", "start_char": 0, "end_char": 1045, "text": "Machine learning in Python with scikit‑learn is a course that builds predictive models using scikit‑learn and provides a practical understanding of machine learning. Learners grasp fundamental concepts, build predictive modeling pipelines, develop intuitions behind models from linear models to gradient‑boosted decision trees, and evaluate model performance. The course offers step‑by‑step lessons that teach learners to be critical about each step of the predictive modeling pipeline, from data preprocessing to model selection and interpretation. It includes practical training through Jupyter notebooks, quizzes and programming exercises. Modules cover the predictive modeling pipeline, selecting the best model, hyperparameter tuning, linear models, decision tree models, ensemble methods and evaluating model performance. The course is accessible without a strong technical background; basic Python knowledge and some experience with NumPy, pandas and Matplotlib are recommended. The MOOC is free and course materials are available online.", "token_count": 139}
{"fragment_id": "F011", "resource_id": "R011", "uv_id": "LO17", "fragment_type": "section", "section_title": "From Database to Big Data (FUN MOOC)", "start_char": 0, "end_char": 1029, "text": "The course ‘From data base to big data’ provides a conceptual framework for understanding modern data systems by exploring major standards. A multidisciplinary introduction offers a strategic vision of the future of information systems around the concepts of mobiquity and Big Data. The course presents fundamental concepts of databases and Big Data with their paradigms and properties (TIPS/ACID, RICE, WHAT/BASE, Google CABS) and explores top‑down and bottom‑up approaches to data integration. Intended as a seven‑week course, it includes short video sequences, quizzes, practical work, discussion forums, and peer‑reviewed exercises. Two packages are available: Discovery (free, with videos, quizzes and forums) and Certifying (which adds peer‑reviewed exercises, weekly live tutoring and a monitored exam). Topics cover spiralist innovation on Big Data systems, data paradigms and Codd’s relational model, SQL2, the Third Date’s manifesto for object‑relational models, ODMG, SQL3, and an overview of NoSQL and NewSQL systems.", "token_count": 145}
{"fragment_id": "F012", "resource_id": "R012", "uv_id": "LO17", "fragment_type": "section", "section_title": "Introductory Statistics 2e (OpenStax)", "start_char": 0, "end_char": 754, "text": "Introductory Statistics 2e introduces the science of collecting, analyzing, interpreting and presenting data. In the section ‘Definitions of Statistics, Probability, and Key Terms’ it explains that statistics is used in everyday life and includes descriptive statistics—organizing and summarizing data using graphs and numbers such as averages—and inferential statistics, which uses probability to draw conclusions from data. A collaborative exercise invites students to record their sleep hours and create a dot plot. The text emphasizes probability as a tool to study randomness and introduces topics such as combinatorics, random variables, probability distributions, Bayesian inference, hypothesis testing, confidence intervals and linear regression.", "token_count": 100}
{"fragment_id": "F013", "resource_id": "R013", "uv_id": "LO17", "fragment_type": "section", "section_title": "Matrix Calculus for Machine Learning and Beyond (18.S096)", "start_char": 0, "end_char": 750, "text": "Matrix Calculus for Machine Learning and Beyond teaches matrix calculus as the next step after univariate and vector calculus, focusing on applications in machine learning and large‑scale optimization. Students learn a coherent approach to matrix calculus that encourages thinking of a matrix holistically rather than as an array of scalars. The course covers techniques to generalize and compute derivatives of important matrix factorizations and other complex operations, and explains how differentiation formulas must be reimagined for large‑scale computing. By re‑emphasizing linearization and the linear algebra at the heart of calculus, the class addresses complicated functions like matrix determinants and solutions of differential equations.", "token_count": 103}
{"fragment_id": "F014", "resource_id": "R014", "uv_id": "LO17", "fragment_type": "section", "section_title": "Introduction to Computer Science and Programming in Python (6.0001)", "start_char": 0, "end_char": 466, "text": "6.0001 Introduction to Computer Science and Programming in Python is intended for students with little or no programming experience. The course provides an understanding of the role computation can play in solving problems and helps students, regardless of their major, feel confident in their ability to write small programs that accomplish useful goals. It uses the Python 3.5 programming language and teaches basic programming concepts and problem‑solving skills.", "token_count": 68}
{"fragment_id": "F015", "resource_id": "R015", "uv_id": "LO17", "fragment_type": "section", "section_title": "OpenIntro Statistics (Textbook)", "start_char": 0, "end_char": 325, "text": "OpenIntro Statistics is a dynamic take on the traditional statistics curriculum and is used from community colleges to the Ivy League. Recommended for college courses and self‑study, the resource provides videos, slides, labs and other materials. Free PDF downloads and additional resources are available through the website.", "token_count": 47}
{"fragment_id": "F016", "resource_id": "R016", "uv_id": "LO17", "fragment_type": "section", "section_title": "Introduction to Modern Statistics (OpenIntro)", "start_char": 0, "end_char": 758, "text": "Introduction to Modern Statistics reimagines the earlier Introduction to Statistics with Randomization and Simulation. It introduces multi‑dimensional thinking early on and emphasizes exploratory data analysis, using visualization, summarization and descriptive models to explore multivariate relationships. The book provides a thorough discussion of simulation‑based inference using randomization and bootstrapping followed by Central Limit Theorem‑based approaches. The second edition adds updated datasets, additional exercises, a new application and updated text and code reflecting best practices. The web‑native book, built with bookdown, offers easy navigation, interactive R tutorials, labs using tidyverse and infer packages, and access to datasets.", "token_count": 95}
{"fragment_id": "F017", "resource_id": "R017", "uv_id": "LO17", "fragment_type": "section", "section_title": "Data Analysis and Visualization in Python for Ecologists (Data Carpentry)", "start_char": 0, "end_char": 455, "text": "Data Analysis and Visualization in Python for Ecologists is an introductory lesson designed for participants with no programming experience. Over about ten hours, learners are taught the basics of Python syntax and the Jupyter notebook interface, importing CSV files, using the pandas package to work with data frames, calculating summary information, and making simple plots. The final lesson demonstrates how to work with databases directly from Python.", "token_count": 67}
{"fragment_id": "F018", "resource_id": "R018", "uv_id": "LO17", "fragment_type": "section", "section_title": "Introduction to Probability and Statistics (18.05)", "start_char": 0, "end_char": 389, "text": "This course provides an elementary introduction to probability and statistics with applications. Topics include basic combinatorics, random variables, probability distributions, Bayesian inference, hypothesis testing, confidence intervals and linear regression. Interactive components such as online reading questions and problem checkers are available through MIT’s Open Learning Library.", "token_count": 46}
