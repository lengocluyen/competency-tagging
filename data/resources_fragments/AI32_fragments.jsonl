{"fragment_id": "F001", "resource_id": "R001", "uv_id": "AI32", "fragment_type": "section", "section_title": "Definitions: System and Control", "start_char": 0, "end_char": 631, "text": "A system is a collection of objects or elements arranged to achieve a goal. Examples of systems include industrial robots, cars, turbines and other machines, as well as biological and social systems. The control action is the deliberate manipulation of a system to make important quantities behave desirably. For instance, a thermostat controls room temperature by turning the heater on and off, and an airplane\u2019s altitude controller adjusts the elevator to follow a desired flight path. In control engineering we identify the system to be controlled, the variables of interest and the actuators that can influence those variables.", "token_count": 98}
{"fragment_id": "F002", "resource_id": "R002", "uv_id": "AI32", "fragment_type": "section", "section_title": "Types of Control Actions", "start_char": 0, "end_char": 833, "text": "Control actions can be open-loop or closed-loop. In an open\u2011loop system the controller applies a command without using feedback to correct for disturbances, so its performance relies on accurate modelling and a predictable environment. Examples include manually setting a car\u2019s throttle to maintain speed on level ground. In contrast, a closed\u2011loop system uses feedback to compare the measured output to a desired reference and adjust the input to reduce the error; this reduces sensitivity to modelling errors and disturbances. Negative feedback is normally used because it subtracts a portion of the output from the input to stabilise the system, whereas positive feedback adds the output and can lead to instability. Common closed\u2011loop examples include thermostats, cruise control in automobiles, and human temperature regulation.", "token_count": 123}
{"fragment_id": "F003", "resource_id": "R003", "uv_id": "AI32", "fragment_type": "section", "section_title": "Control Objectives", "start_char": 0, "end_char": 665, "text": "Control objectives express what we want the closed\u2011loop system to achieve. Key objectives include safety, tracking and regulation. Tracking means forcing the system output to follow a reference signal both in the steady state and during transient conditions. Regulation refers to maintaining a constant output despite disturbances. Good control minimises the steady\u2011state error, provides acceptable transient behaviour (rise time, overshoot, settling time), rejects disturbances and operates within actuator limits. Because real systems have uncertainties and constraints, the controller is designed to balance performance with robustness and practical limitations.", "token_count": 88}
{"fragment_id": "F004", "resource_id": "R004", "uv_id": "AI32", "fragment_type": "section", "section_title": "General Definition of Stability", "start_char": 0, "end_char": 735, "text": "Stability is an implicit objective of control: a closed\u2011loop system is stable if its response does not diverge when subjected to bounded inputs. One common stability criterion is BIBO stability, which requires that any bounded input produce a bounded output. For linear time\u2011invariant systems the closed\u2011loop transfer function can be written as a ratio of polynomials; the locations of its poles determine stability. If all poles have negative real parts the system is asymptotically stable; poles on the imaginary axis indicate marginal stability; and poles with positive real parts lead to instability. Tools such as the Routh\u2013Hurwitz criterion provide a systematic way to check stability without explicitly computing pole locations.", "token_count": 110}
{"fragment_id": "F005", "resource_id": "R005", "uv_id": "AI32", "fragment_type": "section", "section_title": "Locations in s\u2011Plane vs. Time Response", "start_char": 0, "end_char": 699, "text": "The location of system poles in the complex s\u2011plane determines the shape of the time response. A pair of complex conjugate poles produces an oscillatory response whose frequency is given by the imaginary part and whose decay rate is given by the negative real part. Real negative poles yield monotonic exponential responses, while real positive poles cause monotonic instability because the response grows without bound. Poles on the imaginary axis correspond to undamped oscillations and indicate marginal stability. Designers often use root locus and pole\u2011zero maps to visualise how pole locations change with controller gains and to ensure the system meets stability and transient specifications.", "token_count": 105}
{"fragment_id": "F006", "resource_id": "R006", "uv_id": "AI32", "fragment_type": "section", "section_title": "Laplace Transforms", "start_char": 0, "end_char": 754, "text": "Classical control analysis uses the Laplace transform to convert differential equations into algebraic equations in the s\u2011domain. For an nth\u2011order LTI single\u2011input single\u2011output system, the input\u2013output relationship is described by an ordinary differential equation whose coefficients reflect the system\u2019s physical parameters. Applying the Laplace transform with zero initial conditions produces a transfer function G(s) defined as the ratio of the Laplace transform of the output to that of the input. The transfer function is a ratio of polynomials whose roots are called zeros and poles; it characterises the system\u2019s dynamic gain. Partial\u2011fraction expansion can be used to perform the inverse transform and recover the time\u2011domain response from G(s).", "token_count": 108}
{"fragment_id": "F007", "resource_id": "R007", "uv_id": "AI32", "fragment_type": "section", "section_title": "Industrial Robots", "start_char": 0, "end_char": 854, "text": "Robots are machines that perform tasks automatically. Industrial robots are used to carry out repetitive or strenuous tasks such as assembly, welding, packaging and palletising more quickly and accurately than humans, freeing people for safer or more intellectual roles. Collaborative robots (cobots) can work safely alongside humans to increase production efficiency. Research applications include medical robotics to improve patient care and robots for exploring outer space and underwater environments. Robots come in many forms beyond the stereotypical six\u2011axis articulated arm; different types of joints and linkages give rise to various robot architectures. When selecting a robot for a job engineers consider the number of axes (degrees of freedom), the payload a robot can handle and its reach\u2014the spherical workspace within which it can operate.", "token_count": 124}
{"fragment_id": "F008", "resource_id": "R008", "uv_id": "AI32", "fragment_type": "section", "section_title": "Introduction to State Space", "start_char": 0, "end_char": 1007, "text": "State\u2011space representation is a general method for modelling control systems. It describes the system using a set of first\u2011order differential equations organised into matrices. The A matrix represents the system dynamics, B maps the inputs to the states, C maps the states to the outputs and D represents direct feed\u2011through of inputs to outputs. State\u2011space models can represent mechanical, electrical, pneumatic and fluid systems; unlike transfer\u2011function models they explicitly capture internal state variables such as velocities as well as positions. Zeros in the B matrix indicate inputs that do not influence certain states, which affects controllability; zeros in the C matrix indicate states that do not appear in the outputs, affecting observability. Although the transfer\u2011function approach makes it easier to visualise zeros and poles, state\u2011space models are widely used in modern control because they are well suited to multiple\u2011input multiple\u2011output systems and facilitate state feedback design.", "token_count": 146}
{"fragment_id": "F009", "resource_id": "R009", "uv_id": "AI32", "fragment_type": "section", "section_title": "State Space Modeling", "start_char": 0, "end_char": 907, "text": "State\u2011space modelling provides insight into a system\u2019s dynamics by writing the equations of motion in a structured form. The modelling process starts by identifying effort and flow variables\u2014for a mechanical system these include forces, torques, positions and velocities. A mechanical example uses two masses connected by a spring and damper. The state variables include the positions of each mass and their velocities. The equations of motion are derived by applying Newton\u2019s laws and expressing the resulting second\u2011order differential equations as a set of first\u2011order equations. Variable substitution reduces second\u2011order equations to first\u2011order state equations, enabling analysis of controllability and observability. The state\u2011space representation captures the coupling between states (e.g., the motion of mass M1 depends on both X1 and X2) and forms the basis for designing controllers and observers.", "token_count": 129}
{"fragment_id": "F010", "resource_id": "R010", "uv_id": "AI32", "fragment_type": "section", "section_title": "Discrete State Space", "start_char": 0, "end_char": 851, "text": "Discrete state space is the time\u2011discretised form of continuous state\u2011space models. It is useful for numerical computation and digital control. The conversion begins by taking the Laplace transform of the continuous state equations to obtain X(s)=(sI\u2212A)\u22121B u(s). Inverting the transform and sampling the solution at discrete time steps yields equations of the form x[k+1]=A_d x[k]+B_d u[k], where A_d and B_d are state\u2011transition matrices. These matrices are computed using matrix exponentials; B_d can be expressed as A\u22121(A_d\u2212I)B. The discrete model allows iterative prediction of state trajectories and is essential for designing discrete\u2011time controllers. The discrete formulation clarifies the relationship between the continuous\u2011time dynamics and the sampled system and shows how the state at the next step depends on the current state and input.", "token_count": 122}
{"fragment_id": "F011", "resource_id": "R011", "uv_id": "AI32", "fragment_type": "section", "section_title": "Linear Quadratic Controller", "start_char": 0, "end_char": 772, "text": "The Linear Quadratic Controller (LQR) is an optimal control method that works in the discrete state space to minimise a quadratic cost function. Because LQR requires optimisation, the state\u2011space model is converted from continuous to discrete form. The controller computes control inputs that drive the state toward a desired value while minimising a cost that trades off control effort and state error. A simple example illustrates how iterating x[k+1]=Ax[k]+Bu[k] with an appropriate gain matrix leads to convergence of the state to a steady value. LQR and Model Predictive Control are classical optimal controllers; both have been proven in theoretical and real\u2011world applications and provide excellent performance when accurate models and cost functions are available.", "token_count": 114}
{"fragment_id": "F012", "resource_id": "R012", "uv_id": "AI32", "fragment_type": "section", "section_title": "Model Predictive Controller", "start_char": 0, "end_char": 892, "text": "Model Predictive Control (MPC) is an optimal control strategy that solves a finite\u2011horizon optimisation problem at each sampling instant. It uses a discrete state\u2011space model x(k+1)=Ax(k)+Bu(k)+B_d d(k)+w(k), y(k)=Cx(k)+v(k), where process noise w(k) and measurement noise v(k) are explicitly included. MPC considers system constraints and predicts future states and outputs over a prediction horizon; it then computes a sequence of control actions that minimise a cost function subject to the constraints. In practice, MPC filters process and measurement noise using observers such as the Kalman filter, which performs a prediction step and an update step to estimate the true state and its covariance. MPC has been widely applied in process industries, power systems, automotive and aerospace engineering because of its ability to handle multivariable systems, constraints and disturbances.", "token_count": 127}
{"fragment_id": "F013", "resource_id": "R013", "uv_id": "AI32", "fragment_type": "section", "section_title": "Full State Feedback Controller", "start_char": 0, "end_char": 888, "text": "A Full State Feedback Controller, also known as pole placement, is a control method in which all state variables are fed back through a gain matrix K to place the closed\u2011loop poles at desired locations. It is computationally simpler than LQR and MPC and is suited to deterministic systems where noise is not a major concern. The controller\u2019s motivation is that the transient performance is determined by the closed\u2011loop pole locations; by choosing K appropriately the designer can achieve specified overshoot and settling time. Block diagrams and flow diagrams show the open\u2011loop state space containing matrices A, B and C, and the closed\u2011loop state space containing A\u2212BK, B and C. Before applying pole placement the system\u2019s controllability must be verified by constructing the controllability matrix [B, AB, A\u00b2B, \u2026, A^{n\u22121}B]; a nonzero determinant indicates the system is controllable.", "token_count": 138}
{"fragment_id": "F014", "resource_id": "R014", "uv_id": "AI32", "fragment_type": "section", "section_title": "Modeling and Simulation of Dynamic Systems (2.141)", "start_char": 0, "end_char": 805, "text": "This course teaches modeling of multi\u2011domain engineering systems at a level suitable for design and control. Topics include network representation of physical systems, state\u2011space models, energy storage and dissipation, Legendre transforms, nonlinear mechanics and the Lagrangian and Hamiltonian formulations. Applications span electro\u2011mechanical transducers, mechanisms, fluid and thermal systems, chemical processes and integrated system design. Students learn to derive models from first principles, simulate system dynamics and identify properties relevant to control design such as stability and controllability. The course emphasises a unified approach to modeling across mechanical, electrical and fluid domains and prepares students to apply simulation tools to analyse and design complex systems.", "token_count": 104}
{"fragment_id": "F015", "resource_id": "R015", "uv_id": "AI32", "fragment_type": "section", "section_title": "Dynamic Systems & Control (6.241)", "start_char": 0, "end_char": 728, "text": "Dynamic Systems & Control examines linear, discrete\u2011 and continuous\u2011time, multi\u2011input and multi\u2011output systems. It covers state\u2011space models, stability, controllability and observability, transfer function matrices, poles and zeros, feedback compensators, optimal regulation and observer design. The course also introduces least\u2011squares methods, matrix perturbation, internal stability of interconnected systems, measures of control performance and robustness based on singular values. Nonlinear systems are introduced, providing a foundation for advanced control techniques. Students use these concepts to design controllers that ensure desirable properties such as stability and performance for interconnected dynamic systems.", "token_count": 88}
{"fragment_id": "F016", "resource_id": "R016", "uv_id": "AI32", "fragment_type": "section", "section_title": "Robotic Manipulation", "start_char": 0, "end_char": 618, "text": "Robotic Manipulation explores algorithmic approaches to robot manipulation in unstructured environments. It addresses perception, planning, dynamics and control for autonomous object manipulation. The course emphasises combining sensor data with kinematic and dynamic models to plan grasps and motions that achieve desired tasks. Students learn about contact models, force closure, motion planning algorithms and real\u2011time control strategies. Applications range from industrial automation to service robots, and the course provides a foundation for designing systems that can interact robustly with the physical world.", "token_count": 81}
{"fragment_id": "F017", "resource_id": "R017", "uv_id": "AI32", "fragment_type": "section", "section_title": "Underactuated Robotics", "start_char": 0, "end_char": 633, "text": "Underactuated Robotics introduces the dynamics and control of robots that have fewer actuators than degrees of freedom. Students explore nonlinear dynamics of robotic manipulators, underactuated systems such as legged locomotion and underwater robots, and the principles of optimal and robust control. The course emphasises exploiting the natural dynamics of systems rather than suppressing them, teaching computational methods for planning and control that leverage energy efficient motions. Through examples and projects, students learn how to design and control robots that move with agility and efficiency despite underactuation.", "token_count": 86}
{"fragment_id": "F018", "resource_id": "R018", "uv_id": "AI32", "fragment_type": "section", "section_title": "Dynamic Systems Preface (LTI Systems Textbook)", "start_char": 0, "end_char": 917, "text": "This textbook for students of engineering provides a thorough introduction to linear time\u2011invariant dynamic systems. The learning objectives include solving first\u2011, second\u2011 and higher\u2011order ordinary differential equations using time\u2011domain and Laplace\u2011transform methods, analysing frequency response, modelling mechanical and electrical systems and deriving transfer functions. It teaches students to define system stability, natural frequency, damping ratio and other parameters, and to design proportional\u2013integral\u2013derivative (PID) feedback controllers. The text is organised into chapters on first\u2011 and second\u2011order systems, higher\u2011order mechanical systems, classical feedback control, PID controller design and stability methods. Prerequisites include calculus and basic differential equations, making the book suitable for junior engineering students seeking a foundation in dynamic systems analysis and control.", "token_count": 112}
