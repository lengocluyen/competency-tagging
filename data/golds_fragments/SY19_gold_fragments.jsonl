{"uv_id": "SY19", "resource_id": "R001", "fragment_id": "F001", "fragment_type": "section", "section_title": "Introduction to Natural Language Processing", "start_char": 0, "end_char": 438, "token_count": 53, "text": "This graduate-level course provides an introduction to natural language processing (NLP) from a computational perspective. It covers models for syntactic, semantic, and discourse processing and emphasises machine learning and corpus-based methods. Students learn algorithms for fundamental NLP techniques and explore applications such as syntactic parsing, information extraction, machine translation, dialogue systems, and summarization.", "candidates": ["GI_C3_3", "GI_C5_2", "GI_C1_1", "GI_C1_2"], "gold": [{"competency_id": "GI_C3_3", "evidence": {"start": 55, "end": 82, "quote": "natural language processing"}, "evidence_keyword": "Natural language processing"}]}
{"uv_id": "SY19", "resource_id": "R002", "fragment_id": "F002", "fragment_type": "section", "section_title": "Machine Learning: Modeling and Prediction", "start_char": 0, "end_char": 404, "token_count": 52, "text": "This course introduces the principles, algorithms, and applications of machine learning from the perspective of modeling and prediction. It teaches students how to formulate learning problems, represent and evaluate hypotheses, and address challenges of over‑fitting and generalization. Topics include supervised learning and reinforcement learning with applications to image data and temporal sequences.", "candidates": ["GI_C3_3", "GI_C5_2", "GI_C1_1"], "gold": [{"competency_id": "GI_C3_3", "evidence": {"start": 71, "end": 87, "quote": "machine learning"}, "evidence_keyword": "Machine learning"}]}
{"uv_id": "SY19", "resource_id": "R003", "fragment_id": "F003", "fragment_type": "section", "section_title": "Introduction to Computation and Python Programming", "start_char": 0, "end_char": 355, "token_count": 51, "text": "6.0002 continues the introduction to computation begun in 6.0001 and is intended for students with little or no programming experience. The course explains the role of computation in solving problems and helps students gain confidence writing small programs. Using Python 3.5, students learn computational techniques for problem solving and data analysis.", "candidates": ["GI_C1_1", "GI_C3_3", "GI_C4_3"], "gold": []}
{"uv_id": "SY19", "resource_id": "R004", "fragment_id": "F004", "fragment_type": "section", "section_title": "Linear Algebra for Machine Learning", "start_char": 0, "end_char": 255, "token_count": 35, "text": "Linear algebra concepts are a key ingredient for understanding and creating machine learning algorithms. This course reviews linear algebra with applications to probability and statistics and optimization, and provides a full explanation of deep learning.", "candidates": ["GI_C5_1", "GI_C5_2", "GI_C5_3", "GI_C3_3", "GI_C1_1"], "gold": [{"competency_id": "GI_C3_3", "evidence": {"start": 76, "end": 92, "quote": "machine learning"}, "evidence_keyword": "Machine learning"}]}
{"uv_id": "SY19", "resource_id": "R005", "fragment_id": "F005", "fragment_type": "section", "section_title": "Graduate Machine Learning Survey", "start_char": 0, "end_char": 431, "token_count": 60, "text": "6.867 is an introductory graduate course on machine learning. It surveys many concepts, techniques, and algorithms, beginning with classification and linear regression and extending to more advanced topics such as boosting, support vector machines, hidden Markov models, and Bayesian networks. The course aims to provide intuition behind modern machine learning methods and the statistical inference foundations on which they rest.", "candidates": ["GI_C3_3", "GI_C5_2", "GI_C1_1", "GI_C1_4", "GI_C2_1"], "gold": [{"competency_id": "GI_C3_3", "evidence": {"start": 44, "end": 60, "quote": "machine learning"}, "evidence_keyword": "Machine learning"}]}
{"uv_id": "SY19", "resource_id": "R006", "fragment_id": "F006", "fragment_type": "section", "section_title": "Artificial Intelligence: Knowledge Representation and Learning", "start_char": 0, "end_char": 469, "token_count": 57, "text": "This course introduces students to basic knowledge representation, problem‑solving, and learning methods of artificial intelligence. Students learn to develop intelligent systems by assembling solutions to concrete computational problems, understand the role of knowledge representation, problem solving and learning in intelligent‑system engineering, and appreciate the roles of vision and language in understanding human intelligence from a computational perspective.", "candidates": ["GI_C3_1", "GI_C3_3", "GI_C1_1", "GI_C4_3"], "gold": []}
{"uv_id": "SY19", "resource_id": "R007", "fragment_id": "F007", "fragment_type": "section", "section_title": "Introduction to Programming with Python", "start_char": 0, "end_char": 334, "token_count": 50, "text": "Designed for students with little or no programming experience, this course teaches basic programming concepts and aims to provide an understanding of the role computation can play in solving problems. It helps students build confidence in writing small programs and uses the Python 3.5 language to illustrate core computing concepts.", "candidates": ["GI_C1_1", "GI_C4_3"], "gold": []}
{"uv_id": "SY19", "resource_id": "R008", "fragment_id": "F008", "fragment_type": "section", "section_title": "Principles of Data Visualization with ggplot2", "start_char": 0, "end_char": 451, "token_count": 68, "text": "This chapter introduces principles for effective data visualization, focusing on choosing the right type of plot to communicate information. It explains when to use scatter plots, line plots, bar plots and histograms, and teaches readers how to create and refine visualizations in R using the `ggplot2` package. The chapter also outlines how to evaluate and refine visualizations and warns against the misuse of pie charts and three‑dimensional plots.", "candidates": ["GI_C3_3", "GI_C3_2", "GI_C1_1", "GI_C2_1"], "gold": [{"competency_id": "GI_C3_3", "evidence": {"start": 54, "end": 67, "quote": "visualization"}, "evidence_keyword": "Visualization"}]}
{"uv_id": "SY19", "resource_id": "R009", "fragment_id": "F009", "fragment_type": "section", "section_title": "Classification and k-Nearest Neighbors in R", "start_char": 0, "end_char": 578, "token_count": 74, "text": "This chapter provides the first introduction to predictive questions in the book by focusing on classification problems. It defines classification as using variables to predict a categorical response and discusses practical examples such as medical diagnosis and spam detection. Learning objectives include recognising when classification is appropriate, describing training data and interpreting classifier output, computing distances for nearest neighbor classifiers, using k‑nearest neighbors (KNN) classification in R, and integrating data preprocessing with model training.", "candidates": ["GI_C3_3", "GI_C5_2", "GI_C1_1", "GI_C1_2", "GI_C2_1", "GI_C3_2"], "gold": [{"competency_id": "GI_C3_3", "evidence": {"start": 96, "end": 110, "quote": "classification"}, "evidence_keyword": "Classification"}]}
{"uv_id": "SY19", "resource_id": "R010", "fragment_id": "F010", "fragment_type": "section", "section_title": "Tidy Data and Data Wrangling in R", "start_char": 0, "end_char": 522, "token_count": 73, "text": "This chapter is centred on defining tidy data—a data format that is suitable for analysis—and introduces tools for transforming raw data into this format. It presents a real‑world case study and outlines learning objectives such as defining tidy data, discussing advantages of tidy formats, understanding vectors, lists and data frames in R, and using a range of data‑wrangling functions and operators like `pivot_longer`, `pivot_wider`, `separate`, `select`, `filter`, `mutate`, `summarize`, `map`, and logical operators.", "candidates": ["GI_C3_2", "GI_C3_3", "GI_C1_1", "GI_C3_1", "GI_C5_1"], "gold": []}
{"uv_id": "SY19", "resource_id": "R011", "fragment_id": "F011", "fragment_type": "section", "section_title": "Regression and k-Nearest Neighbors Regression", "start_char": 0, "end_char": 597, "token_count": 78, "text": "This chapter continues the exploration of predictive questions by focusing on predicting numerical variables using regression. It introduces regression as a method for predicting numeric response variables and explains the K‑nearest neighbors (K‑NN) regression algorithm. The chapter emphasises splitting data into training, validation and test sets, using workflows and cross‑validation to choose the number of neighbors, and discusses over‑fitting and under‑fitting. It also outlines learning objectives such as recognising when regression is appropriate and interpreting K‑NN regression output.", "candidates": ["GI_C3_3", "GI_C5_2", "GI_C1_1", "GI_C1_2", "GI_C2_1"], "gold": [{"competency_id": "GI_C3_3", "evidence": {"start": 115, "end": 125, "quote": "regression"}, "evidence_keyword": "regression"}]}
{"uv_id": "SY19", "resource_id": "R012", "fragment_id": "F012", "fragment_type": "section", "section_title": "Data Carpentry: Data Cleaning and Visualization Lessons", "start_char": 0, "end_char": 528, "token_count": 72, "text": "The Data Carpentry program develops domain‑specific lessons for teaching researchers the skills needed for data cleaning, management, analysis and visualization. The website notes that all Data Carpentry lessons are distributed under the Creative Commons Attribution (CC BY) license and are free for reuse or adaptation with attribution. Curricula include Astronomy, Ecology, Genomics, Geospatial, Image Processing and Social Science, each designed to teach fundamental data skills using example datasets relevant to the domain.", "candidates": ["GI_C3_2", "GI_C3_3", "GI_C1_1", "GI_C1_2", "GI_C1_4", "GI_C2_1"], "gold": [{"competency_id": "GI_C3_3", "evidence": {"start": 147, "end": 160, "quote": "visualization"}, "evidence_keyword": "Visualization"}]}
{"uv_id": "SY19", "resource_id": "R013", "fragment_id": "F013", "fragment_type": "section", "section_title": "Predictive Modeling with scikit-learn", "start_char": 0, "end_char": 594, "token_count": 76, "text": "This French MOOC provides an in‑depth introduction to predictive modeling with the scikit‑learn Python library. The course teaches fundamental methodological and software tools of machine learning, emphasising the predictive modelling pipeline, model selection, and evaluation. Topics include data preprocessing, choosing models, understanding failure modes and interpretability, and modules covering linear models, decision trees and ensemble models. The course content is licensed under the Creative Commons Attribution (CC BY) license, while learner‑contributed content is under CC BY‑NC‑ND.", "candidates": ["GI_C3_3", "GI_C5_2", "GI_C1_1", "GI_C1_2", "GI_C1_3", "GI_C2_1", "GI_C3_1"], "gold": [{"competency_id": "GI_C3_3", "evidence": {"start": 180, "end": 196, "quote": "machine learning"}, "evidence_keyword": "Machine learning"}]}
{"uv_id": "SY19", "resource_id": "R014", "fragment_id": "F014", "fragment_type": "section", "section_title": "What is Data Science?", "start_char": 0, "end_char": 544, "token_count": 77, "text": "This section defines data science and explains that it studies how to collect, manage, and analyze data in order to derive meaningful information. It notes that data science originated across disciplines including statistics, mathematics, computer science and social science and that modern data scientists require expertise in data collection, management and analysis. The section also highlights that data preparation is often the most time‑consuming part of the data science cycle, emphasising that the field is inherently interdisciplinary.", "candidates": ["GI_C3_3", "GI_C3_2", "GI_C5_2", "GI_C5_1", "GI_C1_1", "GI_C2_1", "GI_C4_1"], "gold": [{"competency_id": "GI_C3_3", "evidence": {"start": 21, "end": 33, "quote": "data science"}, "evidence_keyword": "Data science"}]}
{"uv_id": "SY19", "resource_id": "R015", "fragment_id": "F015", "fragment_type": "section", "section_title": "Python Setup for Data Science and Visualization", "start_char": 0, "end_char": 526, "token_count": 72, "text": "In this section readers learn how to set up and use Python for data science. The learning outcomes include loading data into Python, performing basic data analysis and creating visualizations using libraries like Pandas and Matplotlib. The section introduces Jupyter Notebook (Colab) as a web‑based environment for interactive programming and provides step‑by‑step instructions for installing Colab, writing and running Python code, and understanding the differences between conventional Python and Jupyter notebook execution.", "candidates": ["GI_C1_1", "GI_C3_3", "GI_C3_2", "GI_C1_4", "GI_C4_3"], "gold": [{"competency_id": "GI_C3_3", "evidence": {"start": 177, "end": 190, "quote": "visualization"}, "evidence_keyword": "Visualization"}]}
{"uv_id": "SY19", "resource_id": "R016", "fragment_id": "F016", "fragment_type": "section", "section_title": "Applications of Data Science Across Domains", "start_char": 0, "end_char": 610, "token_count": 88, "text": "This section explores how data science is applied across a variety of fields such as business, finance, public policy, healthcare, engineering and sports. It discusses learning outcomes like explaining the interdisciplinary nature of data science, identifying real‑world examples and recognizing current issues and challenges in the field. The section illustrates how companies such as Walmart and Amazon use big data and machine learning to improve operations, predict demand and reduce delivery times, and notes applications of data science in fraud detection, weather forecasting and the Internet of Things.", "candidates": ["GI_C3_3", "GI_C3_2", "GI_C2_2", "GI_C1_1", "GI_C2_1"], "gold": [{"competency_id": "GI_C3_3", "evidence": {"start": 422, "end": 438, "quote": "machine learning"}, "evidence_keyword": "Machine learning"}]}
