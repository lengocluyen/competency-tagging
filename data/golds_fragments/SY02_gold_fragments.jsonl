{"uv_id": "SY02", "resource_id": "R001", "fragment_id": "F001", "fragment_type": "section", "section_title": "Introduction to Monte Carlo Methods", "start_char": 0, "end_char": 857, "token_count": 136, "text": "Monte Carlo methods use probability, random numbers and computers to solve complex problems that are impossible to model with simple formulas. The Physics 132 lab manual notes that these techniques were first applied in the Manhattan Project and are now used in areas such as finance, cost estimation and resource exploration. A simple example explains how to estimate π by throwing random ‘darts’ at a unit square containing a circle.  The area of the circle divided by the area of the square is π/4. Randomly generated x and y coordinates between 0 and 1 are used as dart positions.  The fraction of darts that fall inside the circle (where √(x2+y2) < 0.5) approximates the ratio of the areas; after many trials this ratio converges to π/4 and multiplying by four yields a reasonable approximation of π.", "candidates": ["GI_C5_2", "GI_C1_1", "GI_C2_1", "GI_C4_1"], "gold": [{"competency_id": "GI_C5_2", "evidence": {"start": 0, "end": 141, "quote": "Monte Carlo methods use probability, random numbers and computers to solve complex problems that are impossible to model with simple formulas"}}], "matched_terms": ["Probability"]}
{"uv_id": "SY02", "resource_id": "R002", "fragment_id": "F002", "fragment_type": "section", "section_title": "Monte Carlo Error Propagation", "start_char": 0, "end_char": 882, "token_count": 126, "text": "This section of the Physics 132 lab manual describes how Monte Carlo sampling can be used to propagate uncertainty in measured quantities.  It begins by reviewing assumptions: the population of possible measurements follows a normal distribution with mean μ and standard deviation σ, and the sample mean ī and sample standard deviation are good estimates of these parameters. The manual lists formulas for the sample mean ī= (1/N)∑xi and sample standard deviation σ=√{1/(N-1)∑(xi−ī)2}, and notes that measurements are assumed to be independent.  It then explains that to propagate error one generates many simulated measurements from the estimated normal distribution and calculates the resulting quantity of interest for each simulated trial.  The distribution of simulated results gives an empirical estimate of the uncertainty of the computed quantity.", "candidates": ["GI_C5_2", "GI_C1_1", "GI_C2_1"], "gold": [{"competency_id": "GI_C5_2", "evidence": {"start": 0, "end": 137, "quote": "This section of the Physics 132 lab manual describes how Monte Carlo sampling can be used to propagate uncertainty in measured quantities"}}], "matched_terms": ["Carlo"]}
{"uv_id": "SY02", "resource_id": "R003", "fragment_id": "F003", "fragment_type": "section", "section_title": "Monte Carlo Simulation in Google Sheets", "start_char": 0, "end_char": 864, "token_count": 129, "text": "This tutorial shows how to perform a simple Monte Carlo simulation using Google Sheets.  The key steps are to calculate the mean and standard deviation of the measured quantities (for example, radius and height of a cylinder), set up a spreadsheet with columns for the trial number and each variable, and then use the spreadsheet’s NORMINV function to draw random values from the estimated normal distribution. For instance, a cell formula like “=NORMINV(RAND(), mean\\_radius, stdev\\_radius)” generates a random radius value.  Each row of the spreadsheet corresponds to one simulation trial; formulas are dragged down to produce many trials.  By repeating the random draws for each trial and calculating the quantity of interest (such as volume), one obtains a distribution of simulated outcomes that can be used to estimate uncertainty.", "candidates": ["GI_C5_2", "GI_C1_1"], "gold": [{"competency_id": "GI_C5_2", "evidence": {"start": 0, "end": 86, "quote": "This tutorial shows how to perform a simple Monte Carlo simulation using Google Sheets"}}], "matched_terms": ["Carlo"]}
{"uv_id": "SY02", "resource_id": "R004", "fragment_id": "F004", "fragment_type": "section", "section_title": "Markov Chains", "start_char": 0, "end_char": 1045, "token_count": 160, "text": "This chapter introduces Markov chains, a type of stochastic process in which the outcome of each experiment depends only on the previous outcome.  The text explains that Andrei A. Markov first studied such processes in the early 1900s.  A transition matrix is used to describe the probabilities of moving between states.  For example, in a small town with telephone providers Mama Bell and Papa Bell, 60 % of Mama Bell customers stay and 40 % switch, while 30 % of Papa Bell customers switch to Mama Bell; this information is represented in a 2×2 transition matrix.  A transition matrix is always square, its entries are non‑negative, and each row sums to 1. The chapter notes that some Markov chains are regular and tend to stabilise in the long run.  In that case repeated multiplication of the transition matrix converges to a fixed probability vector (equilibrium vector).  The equilibrium vector E satisfies E T = E and represents the steady‑state distribution.", "candidates": ["GI_C5_2", "GI_C5_1", "GI_C1_1", "GI_C1_2"], "gold": [{"competency_id": "GI_C5_2", "evidence": {"start": 0, "end": 144, "quote": "This chapter introduces Markov chains, a type of stochastic process in which the outcome of each experiment depends only on the previous outcome"}}], "matched_terms": ["Markov chains"]}
{"uv_id": "SY02", "resource_id": "R005", "fragment_id": "F005", "fragment_type": "section", "section_title": "Tutorial: Monte Carlo Runs", "start_char": 0, "end_char": 909, "token_count": 139, "text": "This tutorial from the Ecosystem Modelling with EwE manual explains how to use the Monte Carlo facility in Ecosim to explore the effects of parameter uncertainty.  Users specify a coefficient of variation (for example CV = 0.4 for all groups) and a number of trials (such as 20) to generate random perturbations of model parameters.  The software then runs the model repeatedly, resampling parameters to create many plausible scenarios. The text notes that the routine employs Monte Carlo and Markov Chain Monte Carlo algorithms to search for parameter combinations that improve the fit to time‑series data.  After running the trials, users can inspect the resulting distributions of outputs or save the results for further analysis.  The chapter cautions that on computers with Apple M processors, the Windows version may be required for the Monte Carlo facility to work correctly.", "candidates": ["GI_C5_2", "GI_C1_1", "GI_C1_2", "GI_C2_1"], "gold": [{"competency_id": "GI_C5_2", "evidence": {"start": 0, "end": 161, "quote": "This tutorial from the Ecosystem Modelling with EwE manual explains how to use the Monte Carlo facility in Ecosim to explore the effects of parameter uncertainty"}}], "matched_terms": ["Carlo"]}
{"uv_id": "SY02", "resource_id": "R006", "fragment_id": "F006", "fragment_type": "section", "section_title": "Markov-Processes I", "start_char": 0, "end_char": 861, "token_count": 126, "text": "These lecture notes introduce discrete‑time Markov processes.  A Markov process is a sequence of random variables X0,X1,… taking values in a state space such that the conditional distribution of the next state depends only on the current state.  The notes define the one‑step transition probability r_{ij} = P(X_{n+1}=j | X_{n}=i) and n‑step transition probabilities r_{ij}(n). They explain that the chain’s future evolution depends only on the present state (the Markov property) and not on the past.  States can be classified as recurrent or transient depending on whether the process returns to them with probability 1.  The lecture also discusses questions about long‑term behaviour, such as whether the Markov chain converges to a steady‑state distribution as n→∞ and how to compute hitting probabilities and expected return times.", "candidates": ["GI_C5_2", "GI_C1_1", "GI_C1_2"], "gold": [{"competency_id": "GI_C5_2", "evidence": {"start": 244, "end": 376, "quote": "  The notes define the one‑step transition probability r_{ij} = P(X_{n+1}=j | X_{n}=i) and n‑step transition probabilities r_{ij}(n)"}}], "matched_terms": ["Probability"]}
{"uv_id": "SY02", "resource_id": "R007", "fragment_id": "F007", "fragment_type": "section", "section_title": "Markov Processes II", "start_char": 0, "end_char": 796, "token_count": 113, "text": "In this continuation of the MIT lecture on Markov processes, the notes review n‑step transition probabilities and derive conditions under which a Markov chain has a unique steady‑state distribution.  A state is positive recurrent if the expected return time is finite, and a Markov chain consisting entirely of positive recurrent states is called positive recurrent.  The lecture introduces birth–death processes as a special class of Markov chains with transitions only between neighbouring states and shows how to compute their stationary distributions.  It presents the steady‑state balance equations πj=Σi πi r_{ij} and explains that when the chain is irreducible and positive recurrent, the distribution of Xn converges to the stationary distribution as n increases.", "candidates": ["GI_C5_2", "GI_C1_1", "GI_C1_2", "GI_C2_1"], "gold": [{"competency_id": "GI_C5_2", "evidence": {"start": 368, "end": 554, "quote": "The lecture introduces birth–death processes as a special class of Markov chains with transitions only between neighbouring states and shows how to compute their stationary distributions"}}], "matched_terms": ["Markov chains"]}
{"uv_id": "SY02", "resource_id": "R008", "fragment_id": "F008", "fragment_type": "section", "section_title": "The Central Limit Theorem for Sample Means", "start_char": 0, "end_char": 830, "token_count": 127, "text": "This OpenStax section states the central limit theorem for sample means: if random samples of size n are taken from any population with mean μ and standard deviation σ, the distribution of the sample mean ī approaches a normal distribution as n increases.  The sampling distribution has mean μ and standard deviation σ/√{n}. An example shows how to approximate the probability that the mean of a sample of 100 measurements lies between 9.5 and 10.5 when the population mean is 10 and the standard deviation is 2.  By standardising to a z‑score and using a normal cumulative distribution function, the probability can be computed numerically.  The page emphasises that the theorem holds regardless of the shape of the original population when the sample size is sufficiently large.", "candidates": ["GI_C5_2", "GI_C1_1"], "gold": [{"competency_id": "GI_C5_2", "evidence": {"start": 350, "end": 462, "quote": "An example shows how to approximate the probability that the mean of a sample of 100 measurements lies between 9"}}], "matched_terms": ["Probability"]}
{"uv_id": "SY02", "resource_id": "R009", "fragment_id": "F009", "fragment_type": "section", "section_title": "The Central Limit Theorem for Sums", "start_char": 0, "end_char": 732, "token_count": 110, "text": "This section extends the central limit theorem to sums.  If independent random variables each have mean μ and standard deviation σ, the sum of n variables has mean nμ and standard deviation √{n} σ; for large n the distribution of the sum is approximately normal. For example, suppose the total weight of 80 packages is studied and individual package weights have mean 90 and standard deviation 20.  The expected total weight is nμ=80×90=7,200 and the standard deviation of the sum is √{80}×20≈178.9.  To find the probability that the sum exceeds 7,500, one computes a z‑score for (7,500 – 7,200)/178.9 and looks up the corresponding tail probability using the normal distribution.", "candidates": ["GI_C5_2", "GI_C1_1", "GI_C2_1"], "gold": [{"competency_id": "GI_C5_2", "evidence": {"start": 525, "end": 625, "quote": "  To find the probability that the sum exceeds 7,500, one computes a z‑score for (7,500 – 7,200)/178"}}], "matched_terms": ["Probability"]}
{"uv_id": "SY02", "resource_id": "R010", "fragment_id": "F010", "fragment_type": "section", "section_title": "Using the Central Limit Theorem", "start_char": 0, "end_char": 724, "token_count": 117, "text": "OpenStax clarifies how to apply the central limit theorem.  It states that the theorem should be used for sample means when calculating the probability that ī lies in an interval and for sums when calculating the probability that ∑X_i lies in an interval.  The theorem should not be used for probabilities involving individual observations. The section explains the law of large numbers, which says that as the sample size grows the sample mean tends to the population mean.  It also provides examples showing how to use the CLT to compute probabilities for sample means and sums, and cautions that the underlying distribution does not need to be normal as long as the sample size is large enough.", "candidates": ["GI_C5_2", "GI_C1_1"], "gold": [{"competency_id": "GI_C5_2", "evidence": {"start": 58, "end": 254, "quote": "  It states that the theorem should be used for sample means when calculating the probability that ī lies in an interval and for sums when calculating the probability that ∑X_i lies in an interval"}}], "matched_terms": ["Probability"]}
{"uv_id": "SY02", "resource_id": "R011", "fragment_id": "F011", "fragment_type": "section", "section_title": "A Single Population Mean using the Normal Distribution", "start_char": 0, "end_char": 795, "token_count": 121, "text": "This section explains how to construct a confidence interval for a population mean when the population standard deviation σ is known.  The point estimate for the mean is the sample mean ī, and the confidence interval has the form ī ± z_{α/2}(σ/√{n}).  The margin of error (error bound for the mean) is z_{α/2}σ/√{n}, where z_{α/2} is the z‑score corresponding to the desired confidence level. The page provides examples: for a 95 % confidence interval (α=0.05) the critical z‑value is approximately 1.96.  If the sample mean is 20 and σ=5 with n=100, the interval is 20±1.96(5/10)=20±0.98, or (19.02,20.98).  The section emphasises proper interpretation: a 95 % confidence level means that 95 % of similarly constructed intervals will contain the true population mean.", "candidates": ["GI_C5_2", "GI_C1_1"], "gold": [], "matched_terms": []}
{"uv_id": "SY02", "resource_id": "R012", "fragment_id": "F012", "fragment_type": "section", "section_title": "A Single Population Mean using the Student t Distribution", "start_char": 0, "end_char": 962, "token_count": 135, "text": "This section recounts the discovery of the Student’s t‑distribution by William S. Gosset (who published under the pen name “Student”).  When the population standard deviation σ is unknown, the t‑distribution with n−1 degrees of freedom is used instead of the normal distribution.  The t‑distribution is symmetric like the normal distribution but has heavier tails; as the degrees of freedom increase it approaches the standard normal distribution. The notes explain that confidence intervals for a population mean are constructed similarly to the z‑intervals but with t_{α/2,n−1} replacing the z‑score and the sample standard deviation s replacing σ.  For example, with n=10 samples and s=2, a 95 % confidence interval for a mean of 50 would use t_{0.025,9}≈2.262 and have half‑width 2.262×(2/√{10}).  The section highlights that as sample size grows, the t‑distribution converges to the normal distribution.", "candidates": ["GI_C5_2", "GI_C1_1", "GI_C2_1"], "gold": [], "matched_terms": []}
{"uv_id": "SY02", "resource_id": "R013", "fragment_id": "F013", "fragment_type": "section", "section_title": "Null and Alternative Hypotheses", "start_char": 0, "end_char": 830, "token_count": 130, "text": "This section defines the null hypothesis H0 as a statement of no effect or no difference, representing the status quo.  The alternative hypothesis H​\\_a is the statement the researcher seeks to support.  In a hypothesis test one must decide whether to reject H0 based on sample evidence; failure to reject H0 does not prove H0 is true. The page provides examples of hypotheses: one might test whether the proportion of voters who will vote yes exceeds 50 %, whether the average GPA of graduates of one college is lower than that of another, or whether the average time to complete a degree has decreased.  In each case H0 and H​\\_a are formulated carefully, and the test will determine whether the observed sample provides sufficient evidence to support the alternative claim.", "candidates": ["GI_C5_2", "GI_C1_1", "GI_C1_2"], "gold": [], "matched_terms": []}
{"uv_id": "SY02", "resource_id": "R014", "fragment_id": "F014", "fragment_type": "section", "section_title": "Outcomes and the Type I and Type II Errors", "start_char": 0, "end_char": 834, "token_count": 139, "text": "This section describes the four possible outcomes of a hypothesis test depending on whether the null hypothesis is true and whether the decision is to reject it.  A Type I error occurs when H0 is rejected even though it is true; its probability is the significance level α.  A Type II error occurs when H0 is not rejected even though it is false; its probability is β. The power of a test is 1 – β and measures the probability of correctly rejecting a false null hypothesis.  The section gives real‑world examples: calling climbing equipment safe when it is unsafe would be a Type II error, while concluding that healthy athletes are using banned substances when they are not would be a Type I error.  The article emphasises choosing α and β to make both types of errors unlikely.", "candidates": ["GI_C5_2", "GI_C1_1", "GI_C1_2", "GI_C2_1"], "gold": [{"competency_id": "GI_C5_2", "evidence": {"start": 161, "end": 272, "quote": "  A Type I error occurs when H0 is rejected even though it is true; its probability is the significance level α"}}], "matched_terms": ["Probability"]}
{"uv_id": "SY02", "resource_id": "R015", "fragment_id": "F015", "fragment_type": "section", "section_title": "Probability Distributions Needed for Hypothesis Testing", "start_char": 0, "end_char": 1052, "token_count": 157, "text": "This OpenStax page summarizes which probability distributions are used for various hypothesis tests and the conditions required.  It states that a normal (z) distribution is used for tests of a population mean when the population standard deviation is known and either the population is normal or the sample size is large; Student’s t distribution is used when σ is unknown and the population is normal.  Tests for a single population proportion use the normal distribution provided that np and n(1–p) are both at least five. The section emphasises verifying the assumptions before performing a test.  It notes that for two‑sample tests of means, if both sample standard deviations are unknown one uses the Student’s t distribution with degrees of freedom given by an appropriate formula.  For two proportions, the z distribution is used as long as each sample has at least five successes and five failures.  These guidelines help practitioners choose the correct distribution for hypothesis tests.", "candidates": ["GI_C5_2", "GI_C1_1", "GI_C1_2", "GI_C1_3", "GI_C2_1"], "gold": [{"competency_id": "GI_C5_2", "evidence": {"start": 0, "end": 127, "quote": "This OpenStax page summarizes which probability distributions are used for various hypothesis tests and the conditions required"}}], "matched_terms": ["Probability"]}
