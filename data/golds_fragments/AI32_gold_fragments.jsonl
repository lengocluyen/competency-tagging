{"uv_id": "AI32", "resource_id": "R001", "fragment_id": "F001", "fragment_type": "section", "section_title": "Definitions: System and Control", "start_char": 0, "end_char": 631, "token_count": 98, "text": "A system is a collection of objects or elements arranged to achieve a goal. Examples of systems include industrial robots, cars, turbines and other machines, as well as biological and social systems. The control action is the deliberate manipulation of a system to make important quantities behave desirably. For instance, a thermostat controls room temperature by turning the heater on and off, and an airplane’s altitude controller adjusts the elevator to follow a desired flight path. In control engineering we identify the system to be controlled, the variables of interest and the actuators that can influence those variables.", "candidates": ["GI_C4_2", "GI_C4_1", "GI_C2_2", "GI_C3_1", "GI_C2_1", "GI_C1_1"], "gold": []}
{"uv_id": "AI32", "resource_id": "R002", "fragment_id": "F002", "fragment_type": "section", "section_title": "Types of Control Actions", "start_char": 0, "end_char": 833, "token_count": 123, "text": "Control actions can be open-loop or closed-loop. In an open‑loop system the controller applies a command without using feedback to correct for disturbances, so its performance relies on accurate modelling and a predictable environment. Examples include manually setting a car’s throttle to maintain speed on level ground. In contrast, a closed‑loop system uses feedback to compare the measured output to a desired reference and adjust the input to reduce the error; this reduces sensitivity to modelling errors and disturbances. Negative feedback is normally used because it subtracts a portion of the output from the input to stabilise the system, whereas positive feedback adds the output and can lead to instability. Common closed‑loop examples include thermostats, cruise control in automobiles, and human temperature regulation.", "candidates": ["GI_C4_2", "GI_C4_1", "GI_C1_1", "GI_C1_2", "GI_C2_1"], "gold": [{"competency_id": "GI_C4_1", "evidence": {"start": 529, "end": 719, "quote": "Negative feedback is normally used because it subtracts a portion of the output from the input to stabilise the system, whereas positive feedback adds the output and can lead to instability."}}]}
{"uv_id": "AI32", "resource_id": "R003", "fragment_id": "F003", "fragment_type": "section", "section_title": "Control Objectives", "start_char": 0, "end_char": 665, "token_count": 88, "text": "Control objectives express what we want the closed‑loop system to achieve. Key objectives include safety, tracking and regulation. Tracking means forcing the system output to follow a reference signal both in the steady state and during transient conditions. Regulation refers to maintaining a constant output despite disturbances. Good control minimises the steady‑state error, provides acceptable transient behaviour (rise time, overshoot, settling time), rejects disturbances and operates within actuator limits. Because real systems have uncertainties and constraints, the controller is designed to balance performance with robustness and practical limitations.", "candidates": ["GI_C4_2", "GI_C4_1", "GI_C1_1", "GI_C1_2", "GI_C2_1", "GI_C5_3"], "gold": [{"competency_id": "GI_C4_2", "evidence": {"start": 516, "end": 665, "quote": "Because real systems have uncertainties and constraints, the controller is designed to balance performance with robustness and practical limitations."}}]}
{"uv_id": "AI32", "resource_id": "R004", "fragment_id": "F004", "fragment_type": "section", "section_title": "General Definition of Stability", "start_char": 0, "end_char": 735, "token_count": 110, "text": "Stability is an implicit objective of control: a closed‑loop system is stable if its response does not diverge when subjected to bounded inputs. One common stability criterion is BIBO stability, which requires that any bounded input produce a bounded output. For linear time‑invariant systems the closed‑loop transfer function can be written as a ratio of polynomials; the locations of its poles determine stability. If all poles have negative real parts the system is asymptotically stable; poles on the imaginary axis indicate marginal stability; and poles with positive real parts lead to instability. Tools such as the Routh–Hurwitz criterion provide a systematic way to check stability without explicitly computing pole locations.", "candidates": ["GI_C4_2", "GI_C4_1", "GI_C1_1", "GI_C2_1"], "gold": [{"competency_id": "GI_C4_2", "evidence": {"start": 259, "end": 416, "quote": "For linear time‑invariant systems the closed‑loop transfer function can be written as a ratio of polynomials; the locations of its poles determine stability."}}, {"competency_id": "GI_C4_1", "evidence": {"start": 259, "end": 416, "quote": "For linear time‑invariant systems the closed‑loop transfer function can be written as a ratio of polynomials; the locations of its poles determine stability."}}]}
{"uv_id": "AI32", "resource_id": "R005", "fragment_id": "F005", "fragment_type": "section", "section_title": "Locations in s-Plane vs. Time Response", "start_char": 0, "end_char": 699, "token_count": 105, "text": "The location of system poles in the complex s‑plane determines the shape of the time response. A pair of complex conjugate poles produces an oscillatory response whose frequency is given by the imaginary part and whose decay rate is given by the negative real part. Real negative poles yield monotonic exponential responses, while real positive poles cause monotonic instability because the response grows without bound. Poles on the imaginary axis correspond to undamped oscillations and indicate marginal stability. Designers often use root locus and pole‑zero maps to visualise how pole locations change with controller gains and to ensure the system meets stability and transient specifications.", "candidates": ["GI_C4_1", "GI_C4_2", "GI_C1_2", "GI_C2_1", "GI_C1_1"], "gold": [{"competency_id": "GI_C4_1", "evidence": {"start": 421, "end": 517, "quote": "Poles on the imaginary axis correspond to undamped oscillations and indicate marginal stability."}}]}
{"uv_id": "AI32", "resource_id": "R006", "fragment_id": "F006", "fragment_type": "section", "section_title": "Laplace Transforms", "start_char": 0, "end_char": 754, "token_count": 108, "text": "Classical control analysis uses the Laplace transform to convert differential equations into algebraic equations in the s‑domain. For an nth‑order LTI single‑input single‑output system, the input–output relationship is described by an ordinary differential equation whose coefficients reflect the system’s physical parameters. Applying the Laplace transform with zero initial conditions produces a transfer function G(s) defined as the ratio of the Laplace transform of the output to that of the input. The transfer function is a ratio of polynomials whose roots are called zeros and poles; it characterises the system’s dynamic gain. Partial‑fraction expansion can be used to perform the inverse transform and recover the time‑domain response from G(s).", "candidates": ["GI_C4_2", "GI_C4_1", "GI_C2_2", "GI_C5_1", "GI_C2_1", "GI_C1_1"], "gold": []}
{"uv_id": "AI32", "resource_id": "R007", "fragment_id": "F007", "fragment_type": "section", "section_title": "Industrial Robots", "start_char": 0, "end_char": 854, "token_count": 124, "text": "Robots are machines that perform tasks automatically. Industrial robots are used to carry out repetitive or strenuous tasks such as assembly, welding, packaging and palletising more quickly and accurately than humans, freeing people for safer or more intellectual roles. Collaborative robots (cobots) can work safely alongside humans to increase production efficiency. Research applications include medical robotics to improve patient care and robots for exploring outer space and underwater environments. Robots come in many forms beyond the stereotypical six‑axis articulated arm; different types of joints and linkages give rise to various robot architectures. When selecting a robot for a job engineers consider the number of axes (degrees of freedom), the payload a robot can handle and its reach—the spherical workspace within which it can operate.", "candidates": ["GI_C4_2", "GI_C4_1", "GI_C1_4", "GI_C1_1"], "gold": []}
{"uv_id": "AI32", "resource_id": "R008", "fragment_id": "F008", "fragment_type": "section", "section_title": "Introduction to State Space", "start_char": 0, "end_char": 1007, "token_count": 146, "text": "State‑space representation is a general method for modelling control systems. It describes the system using a set of first‑order differential equations organised into matrices. The A matrix represents the system dynamics, B maps the inputs to the states, C maps the states to the outputs and D represents direct feed‑through of inputs to outputs. State‑space models can represent mechanical, electrical, pneumatic and fluid systems; unlike transfer‑function models they explicitly capture internal state variables such as velocities as well as positions. Zeros in the B matrix indicate inputs that do not influence certain states, which affects controllability; zeros in the C matrix indicate states that do not appear in the outputs, affecting observability. Although the transfer‑function approach makes it easier to visualise zeros and poles, state‑space models are widely used in modern control because they are well suited to multiple‑input multiple‑output systems and facilitate state feedback design.", "candidates": ["GI_C4_2", "GI_C4_1", "GI_C5_1", "GI_C2_2", "GI_C4_3", "GI_C2_1", "GI_C1_1"], "gold": [{"competency_id": "GI_C4_2", "evidence": {"start": 0, "end": 77, "quote": "State‑space representation is a general method for modelling control systems."}}]}
{"uv_id": "AI32", "resource_id": "R009", "fragment_id": "F009", "fragment_type": "section", "section_title": "State Space Modeling", "start_char": 0, "end_char": 907, "token_count": 129, "text": "State‑space modelling provides insight into a system’s dynamics by writing the equations of motion in a structured form. The modelling process starts by identifying effort and flow variables—for a mechanical system these include forces, torques, positions and velocities. A mechanical example uses two masses connected by a spring and damper. The state variables include the positions of each mass and their velocities. The equations of motion are derived by applying Newton’s laws and expressing the resulting second‑order differential equations as a set of first‑order equations. Variable substitution reduces second‑order equations to first‑order state equations, enabling analysis of controllability and observability. The state‑space representation captures the coupling between states (e.g., the motion of mass M1 depends on both X1 and X2) and forms the basis for designing controllers and observers.", "candidates": ["GI_C4_2", "GI_C4_1", "GI_C4_3", "GI_C1_2", "GI_C2_1", "GI_C4_4", "GI_C1_1"], "gold": []}
{"uv_id": "AI32", "resource_id": "R010", "fragment_id": "F010", "fragment_type": "section", "section_title": "Discrete State Space", "start_char": 0, "end_char": 851, "token_count": 122, "text": "Discrete state space is the time‑discretised form of continuous state‑space models. It is useful for numerical computation and digital control. The conversion begins by taking the Laplace transform of the continuous state equations to obtain X(s)=(sI−A)−1B u(s). Inverting the transform and sampling the solution at discrete time steps yields equations of the form x[k+1]=A_d x[k]+B_d u[k], where A_d and B_d are state‑transition matrices. These matrices are computed using matrix exponentials; B_d can be expressed as A−1(A_d−I)B. The discrete model allows iterative prediction of state trajectories and is essential for designing discrete‑time controllers. The discrete formulation clarifies the relationship between the continuous‑time dynamics and the sampled system and shows how the state at the next step depends on the current state and input.", "candidates": ["GI_C4_1", "GI_C4_2", "GI_C2_2", "GI_C5_1", "GI_C1_1", "GI_C3_3"], "gold": []}
{"uv_id": "AI32", "resource_id": "R011", "fragment_id": "F011", "fragment_type": "section", "section_title": "Linear Quadratic Controller", "start_char": 0, "end_char": 772, "token_count": 114, "text": "The Linear Quadratic Controller (LQR) is an optimal control method that works in the discrete state space to minimise a quadratic cost function. Because LQR requires optimisation, the state‑space model is converted from continuous to discrete form. The controller computes control inputs that drive the state toward a desired value while minimising a cost that trades off control effort and state error. A simple example illustrates how iterating x[k+1]=Ax[k]+Bu[k] with an appropriate gain matrix leads to convergence of the state to a steady value. LQR and Model Predictive Control are classical optimal controllers; both have been proven in theoretical and real‑world applications and provide excellent performance when accurate models and cost functions are available.", "candidates": ["GI_C4_2", "GI_C4_1", "GI_C3_3", "GI_C5_1", "GI_C5_3", "GI_C2_1", "GI_C1_1"], "gold": [{"competency_id": "GI_C4_2", "evidence": {"start": 0, "end": 144, "quote": "The Linear Quadratic Controller (LQR) is an optimal control method that works in the discrete state space to minimise a quadratic cost function."}}]}
{"uv_id": "AI32", "resource_id": "R012", "fragment_id": "F012", "fragment_type": "section", "section_title": "Model Predictive Controller", "start_char": 0, "end_char": 892, "token_count": 127, "text": "Model Predictive Control (MPC) is an optimal control strategy that solves a finite‑horizon optimisation problem at each sampling instant. It uses a discrete state‑space model x(k+1)=Ax(k)+Bu(k)+B_d d(k)+w(k), y(k)=Cx(k)+v(k), where process noise w(k) and measurement noise v(k) are explicitly included. MPC considers system constraints and predicts future states and outputs over a prediction horizon; it then computes a sequence of control actions that minimise a cost function subject to the constraints. In practice, MPC filters process and measurement noise using observers such as the Kalman filter, which performs a prediction step and an update step to estimate the true state and its covariance. MPC has been widely applied in process industries, power systems, automotive and aerospace engineering because of its ability to handle multivariable systems, constraints and disturbances.", "candidates": ["GI_C4_2", "GI_C4_1", "GI_C1_2", "GI_C2_1", "GI_C3_3", "GI_C4_4", "GI_C5_3", "GI_C5_2", "GI_C1_1"], "gold": [{"competency_id": "GI_C4_2", "evidence": {"start": 0, "end": 137, "quote": "Model Predictive Control (MPC) is an optimal control strategy that solves a finite‑horizon optimisation problem at each sampling instant."}}]}
{"uv_id": "AI32", "resource_id": "R013", "fragment_id": "F013", "fragment_type": "section", "section_title": "Full State Feedback Controller", "start_char": 0, "end_char": 888, "token_count": 138, "text": "A Full State Feedback Controller, also known as pole placement, is a control method in which all state variables are fed back through a gain matrix K to place the closed‑loop poles at desired locations. It is computationally simpler than LQR and MPC and is suited to deterministic systems where noise is not a major concern. The controller’s motivation is that the transient performance is determined by the closed‑loop pole locations; by choosing K appropriately the designer can achieve specified overshoot and settling time. Block diagrams and flow diagrams show the open‑loop state space containing matrices A, B and C, and the closed‑loop state space containing A−BK, B and C. Before applying pole placement the system’s controllability must be verified by constructing the controllability matrix [B, AB, A²B, …, A^{n−1}B]; a nonzero determinant indicates the system is controllable.", "candidates": ["GI_C4_2", "GI_C4_1", "GI_C1_1", "GI_C5_1", "GI_C2_1"], "gold": []}
{"uv_id": "AI32", "resource_id": "R014", "fragment_id": "F014", "fragment_type": "section", "section_title": "Modeling and Simulation of Dynamic Systems", "start_char": 0, "end_char": 805, "token_count": 104, "text": "This course teaches modeling of multi‑domain engineering systems at a level suitable for design and control. Topics include network representation of physical systems, state‑space models, energy storage and dissipation, Legendre transforms, nonlinear mechanics and the Lagrangian and Hamiltonian formulations. Applications span electro‑mechanical transducers, mechanisms, fluid and thermal systems, chemical processes and integrated system design. Students learn to derive models from first principles, simulate system dynamics and identify properties relevant to control design such as stability and controllability. The course emphasises a unified approach to modeling across mechanical, electrical and fluid domains and prepares students to apply simulation tools to analyse and design complex systems.", "candidates": ["GI_C4_1", "GI_C4_2", "GI_C2_2", "GI_C1_2", "GI_C2_1", "GI_C4_3", "GI_C1_4", "GI_C5_3", "GI_C1_1"], "gold": [{"competency_id": "GI_C4_1", "evidence": {"start": 618, "end": 805, "quote": "The course emphasises a unified approach to modeling across mechanical, electrical and fluid domains and prepares students to apply simulation tools to analyse and design complex systems."}}, {"competency_id": "GI_C4_2", "evidence": {"start": 0, "end": 108, "quote": "This course teaches modeling of multi‑domain engineering systems at a level suitable for design and control."}}]}
{"uv_id": "AI32", "resource_id": "R015", "fragment_id": "F015", "fragment_type": "section", "section_title": "Dynamic Systems & Control", "start_char": 0, "end_char": 728, "token_count": 88, "text": "Dynamic Systems & Control examines linear, discrete‑ and continuous‑time, multi‑input and multi‑output systems. It covers state‑space models, stability, controllability and observability, transfer function matrices, poles and zeros, feedback compensators, optimal regulation and observer design. The course also introduces least‑squares methods, matrix perturbation, internal stability of interconnected systems, measures of control performance and robustness based on singular values. Nonlinear systems are introduced, providing a foundation for advanced control techniques. Students use these concepts to design controllers that ensure desirable properties such as stability and performance for interconnected dynamic systems.", "candidates": ["GI_C4_1", "GI_C4_2", "GI_C5_1", "GI_C2_1", "GI_C1_1"], "gold": [{"competency_id": "GI_C4_1", "evidence": {"start": 576, "end": 728, "quote": "Students use these concepts to design controllers that ensure desirable properties such as stability and performance for interconnected dynamic systems."}}, {"competency_id": "GI_C4_2", "evidence": {"start": 0, "end": 111, "quote": "Dynamic Systems & Control examines linear, discrete‑ and continuous‑time, multi‑input and multi‑output systems."}}]}
{"uv_id": "AI32", "resource_id": "R016", "fragment_id": "F016", "fragment_type": "section", "section_title": "Robotic Manipulation", "start_char": 0, "end_char": 618, "token_count": 81, "text": "Robotic Manipulation explores algorithmic approaches to robot manipulation in unstructured environments. It addresses perception, planning, dynamics and control for autonomous object manipulation. The course emphasises combining sensor data with kinematic and dynamic models to plan grasps and motions that achieve desired tasks. Students learn about contact models, force closure, motion planning algorithms and real‑time control strategies. Applications range from industrial automation to service robots, and the course provides a foundation for designing systems that can interact robustly with the physical world.", "candidates": ["GI_C4_2", "GI_C4_1", "GI_C1_1", "GI_C2_2", "GI_C2_1", "GI_C4_4"], "gold": [{"competency_id": "GI_C4_2", "evidence": {"start": 105, "end": 196, "quote": "It addresses perception, planning, dynamics and control for autonomous object manipulation."}}]}
{"uv_id": "AI32", "resource_id": "R017", "fragment_id": "F017", "fragment_type": "section", "section_title": "Underactuated Robotics", "start_char": 0, "end_char": 633, "token_count": 86, "text": "Underactuated Robotics introduces the dynamics and control of robots that have fewer actuators than degrees of freedom. Students explore nonlinear dynamics of robotic manipulators, underactuated systems such as legged locomotion and underwater robots, and the principles of optimal and robust control. The course emphasises exploiting the natural dynamics of systems rather than suppressing them, teaching computational methods for planning and control that leverage energy efficient motions. Through examples and projects, students learn how to design and control robots that move with agility and efficiency despite underactuation.", "candidates": ["GI_C4_2", "GI_C4_1", "GI_C2_2", "GI_C1_1"], "gold": [{"competency_id": "GI_C4_2", "evidence": {"start": 120, "end": 301, "quote": "Students explore nonlinear dynamics of robotic manipulators, underactuated systems such as legged locomotion and underwater robots, and the principles of optimal and robust control."}}]}
{"uv_id": "AI32", "resource_id": "R018", "fragment_id": "F018", "fragment_type": "section", "section_title": "Dynamic Systems Preface", "start_char": 0, "end_char": 917, "token_count": 112, "text": "This textbook for students of engineering provides a thorough introduction to linear time‑invariant dynamic systems. The learning objectives include solving first‑, second‑ and higher‑order ordinary differential equations using time‑domain and Laplace‑transform methods, analysing frequency response, modelling mechanical and electrical systems and deriving transfer functions. It teaches students to define system stability, natural frequency, damping ratio and other parameters, and to design proportional–integral–derivative (PID) feedback controllers. The text is organised into chapters on first‑ and second‑order systems, higher‑order mechanical systems, classical feedback control, PID controller design and stability methods. Prerequisites include calculus and basic differential equations, making the book suitable for junior engineering students seeking a foundation in dynamic systems analysis and control.", "candidates": ["GI_C4_1", "GI_C4_2", "GI_C5_1", "GI_C1_1"], "gold": [{"competency_id": "GI_C4_1", "evidence": {"start": 0, "end": 116, "quote": "This textbook for students of engineering provides a thorough introduction to linear time‑invariant dynamic systems."}}, {"competency_id": "GI_C4_2", "evidence": {"start": 0, "end": 116, "quote": "This textbook for students of engineering provides a thorough introduction to linear time‑invariant dynamic systems."}}]}
